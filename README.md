# Book_data_crawling

## 목표
1. 인공지능 학습에 필요한 각 태그별 책 이미지 정보 수집 <br> 
2. 교보문고 각 카테고리 별 이미지, 이미지url , title , 작가 , 출판사 , 한줄평 데이터 수집 <br> 
<br>
<br>
<br>

## 현재까지 진행상황 

1/20 : 기본적인 접근 및 크롤링 단계 구조화 완료 
<br>
1/21 : 기본적인 이미지 접근 및 이미지 수집 폴더 생성 + 다운 코드 작성 
<br> 
1/22 : 이미지 다운 문제 해결 + 전반적인 진행 흐름 재설정 
<br> 
1/23 : Frame을 빠져나와 상세화면으로 돌아가기 설정 완료 
<br>
1/24 : 전반적인 리팩토링, 한 페이지의 이미지들 크롤링 작업화 완료 + 다음 페이지로 이동 부분 구현화 ( 세부 작업 필요 ) 
<br>
1/25 : 각 index를 구분지어, 해당 index조건이 충족되었을 때 다음페이지로 이동하도록 설정하기 완료 ( 성능부분은 글쎄... 이후, 리팩토링 작업을 통한 최적화 작업 진행하면 더 좋은 성능을 뽑아낼수 있을것으로 예상) 
<br> 
1/27 : 데이터 수집 이후, 각 예외사항에 대한 처리 (큰 이미지 수집이 불가할 경우) 
<br> 
1/28 : 19세 이상책들의 경우 Alert표시로 인해 데이터 수집이 불가하여 해당 부분에대한 예외처리 
<br>
<br>
<br>
2/5~6 : 이미지를 제외한 책 정보 관련 크롤링 단계 구조화 완료
## 문제점 
1/21 이미지 path 접근까지 완료하였는데 이미지 수집이 진행되지 않고 없는 요소라고 에러가 뜸 
<br> 
1/23 이미지 수집 후, 창을 닫고 이전 화면으로 돌아가고 싶은데, Frame 설정을 해제해 줘도 driver.back()이 작동하지 않음  <br>
1/25 수집과정에서 크게보기가 없어 path가 달라 수집이 안되는 경우 발생 , title 명에 / 이 포함되어 있어 해당 폴더에 들어가지 않고 경로로 판단하여 저장이 안되는 경우 발생 
<br>
<br>
<br>
2/5~6 : while문 관련:<br>
        while문 이용해 루프 만드는 중, 원하는 클래스/노드/태그의 존재여부 파악하는 코드 작성이 어려워 멘토님께 도움 요청
<br>
19세 이상의 책 관련:<br>
alert 창의 발생 여부로 19세 이상의 책 판단하고자 함,<br>
try문 이용. indent문제 발생

    
## 해결
1/22 : 각 웹 페이지안에 페이지를 띄운형태로 존재하여 dirver.switch_to.frame을 이용해 해당 frame으로 접근을 시도해야했음 
<br>
1/24 : 상세보기 이동으로 인한 history가 중첩되어 있는것으로 추정됨, 2번을 하니 뒤로가기가 제대로 작동이 되었음 
<br>
1/25 : title을 str()로 문자열 변환을하여 해당 부분 문제 해결 / try execpt문으로 수정하여 해당 오류 작성시 해당 책의 타이틀만 표시해 따로 정보수집할 수 있도록 조치 <br> 
작은 이미지 수집도 가능하지만, 그러기엔 이미지 학습을 진행할때 제대로 학습진행이 안될것 같았고, 이에 더해 많은것이 아닌 해당 카테고리별 10개 안으로 발생했기에 해당 부분 이렇게 수정하기로 결정하였음 <br> 
<br>
<br>
2/5~6 : while문 관련:<br>
xpath가 아닌 selector를 이용하면 된다.

## 개선 방안 
1. Selenium + BeautifulSoup을 활용하여 Selenium으로 페이지 넘겨주고, BeautifulSoup로 데이터 수집하면 현재보다 더 빠르게 진행할수있지않을까 라는 고민 <br> 
2. 현재는 단일 데이터이기에 단일 프로세싱으로 진행하였지만, 이후 DB관련 데이터들을 크롤링할때는 multiProcessing을 통해 데이터 크롤링을 하면 더 좋은 성능을 낼 수 있을것으로 예상 (Metex 예방) 


# DB데이터 적재 크롤링 
## 목표
1. title , 지은이 , 출판사 , 키워드 , 이미지uri , 상세정보창uri 순으로 데이터 저장 진행 <br> 
2. 각 def를 나눠 text / uri 저장으로 구분지어 csv에 순서에 맞게 저장할 계획 

## 현재 진행상황
1/31 : 각 def를 나눠 텍스트 부분부터 하여 작성을 진행중에 있음 
<br> 
2/4 : 각 파트별로 데이터 수집 후 CSV저장 까지 완료 

## 문제점
1/31 : 계획 당시 multiprocessing으로 진행하고자 하였으나 구조를 다시 뜯어보며 분석해보니, 해당 방법으로 할바엔 차라리 단일 프로세싱으로 진행하는것과 큰차이가 없어보였음
<br>
<br> 
1/31 : 키워드 box에 있는 키워드들을 어떻게 하나씩 저장할지에 대해 현재 고민진행중
<br>
2/4 : 너무 목적에 충실한 코드로 보여, 해당 부분 조금 더 리팩토링할 부분이 없을까 현재 고민하며 수정작업 진행해야할것으로 생각중 
## 해결 

## 개선방안 
multiprocessing으로 하였을때의 효율보다 현재 페이지 분석을하였을때 단일로 실행하는 것과의 차이점이 크게없어보여 selenium으로 재 진행
